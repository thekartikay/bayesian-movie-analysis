{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta[1]</th>\n",
       "      <th>beta[2]</th>\n",
       "      <th>beta[3]</th>\n",
       "      <th>beta[4]</th>\n",
       "      <th>beta[5]</th>\n",
       "      <th>beta[6]</th>\n",
       "      <th>beta[7]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.79368</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.204492</td>\n",
       "      <td>0.230418</td>\n",
       "      <td>0.026620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.16414</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>-0.138506</td>\n",
       "      <td>-0.004520</td>\n",
       "      <td>-0.064790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.61404</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.305254</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.042974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.70308</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.174560</td>\n",
       "      <td>0.282329</td>\n",
       "      <td>-0.037926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.01021</td>\n",
       "      <td>0.016935</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.482652</td>\n",
       "      <td>-0.014611</td>\n",
       "      <td>0.166988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     beta0   beta[1]   beta[2]   beta[3]   beta[4]   beta[5]   beta[6]  \\\n",
       "0 -4.79368  0.013326  0.000791  0.000045  0.000557  0.204492  0.230418   \n",
       "1 -4.16414  0.010172  0.000816  0.000029  0.000439 -0.138506 -0.004520   \n",
       "2 -4.61404  0.011930  0.000726  0.000189  0.000492  0.305254  0.030620   \n",
       "3 -4.70308  0.011693  0.000938  0.000140  0.000454  0.174560  0.282329   \n",
       "4 -5.01021  0.016935  0.000637 -0.000013  0.000553  0.482652 -0.014611   \n",
       "\n",
       "    beta[7]  \n",
       "0  0.026620  \n",
       "1 -0.064790  \n",
       "2  0.042974  \n",
       "3 -0.037926  \n",
       "4  0.166988  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the output from JAGS\n",
    "model = pd.read_csv('dataset/model.csv')\n",
    "model = model[model.columns[0:8]]\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>actor_name_score</th>\n",
       "      <th>studio_score</th>\n",
       "      <th>crew_member_score</th>\n",
       "      <th>season_autumn</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_summer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>1547.013755</td>\n",
       "      <td>1102.121751</td>\n",
       "      <td>6859.013397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>5188.166899</td>\n",
       "      <td>2155.532879</td>\n",
       "      <td>10077.125770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>1336.034036</td>\n",
       "      <td>574.998727</td>\n",
       "      <td>5118.766659</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>3169.442028</td>\n",
       "      <td>185.550221</td>\n",
       "      <td>4803.724619</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>3423.428882</td>\n",
       "      <td>2154.021479</td>\n",
       "      <td>5211.644889</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   runtime  actor_name_score  studio_score  crew_member_score  season_autumn  \\\n",
       "0      148       1547.013755   1102.121751        6859.013397              1   \n",
       "1      165       5188.166899   2155.532879       10077.125770              0   \n",
       "2      132       1336.034036    574.998727        5118.766659              0   \n",
       "3      141       3169.442028    185.550221        4803.724619              0   \n",
       "4      151       3423.428882   2154.021479        5211.644889              0   \n",
       "\n",
       "   season_spring  season_summer  \n",
       "0              0              0  \n",
       "1              0              1  \n",
       "2              1              0  \n",
       "3              1              0  \n",
       "4              1              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test set\n",
    "test = pd.read_csv('dataset/test.csv').drop('Unnamed: 0',axis=1)\n",
    "cols = ['runtime', 'actor_name_score', 'studio_score','crew_member_score', \n",
    "          'season_autumn', 'season_spring','season_summer']\n",
    "test = test[cols]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966771602630615\n",
      "Accuracy: 0.7340529931305201 , Recall: 0.11643835616438356\n",
      "Predicted  0.0  1.0   All\n",
      "True                     \n",
      "0          714   13   727\n",
      "1          258   34   292\n",
      "All        972   47  1019\n",
      "You used 0.5 threshold... Would you like to get the results for another one? ([y]/n) 0.1\n",
      "Enter threshold: 0.01\n",
      "Accuracy: 0.30225711481844947 , Recall: 1.0\n",
      "Predicted  0.0   1.0   All\n",
      "True                      \n",
      "0           16   711   727\n",
      "1            0   292   292\n",
      "All         16  1003  1019\n",
      "AUC Score: 0.5110041265474553\n",
      "You used 0.01 threshold... Would you like to get the results for another one? ([y]/n) y\n",
      "Enter threshold: 0.08\n",
      "Accuracy: 0.718351324828263 , Recall: 0.6643835616438356\n",
      "Predicted  0.0  1.0   All\n",
      "True                     \n",
      "0          538  189   727\n",
      "1           98  194   292\n",
      "All        636  383  1019\n",
      "AUC Score: 0.7022055359801022\n",
      "You used 0.08 threshold... Would you like to get the results for another one? ([y]/n) n\n"
     ]
    }
   ],
   "source": [
    "# Thanks to Pedro Uria and Sean Pelli.\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "\n",
    "USE_MODE, USE_MODE_THRESHOLD = False, 0.5  # This means use mode as coefficient and do regular logistic regression.\n",
    "# logits greater or equal than THRESHOLD are considered to be fake reviews\n",
    "USE_SAMPLES = True  # This means getting one z for each sampled betas, then use the mode of distribution and apply\n",
    "APPLY_MODE, APPLY_MEAN, APPLY_MAX, USE_SAMPLES_THRESHOLD = True, False, False, 0.5  # sigmoid on this (APPLY_MODE)\n",
    "# Another option is getting one logit for each sample and using the mean (APPLY_MEAN)\n",
    "# Another option is getting one prediction for each sample and then using the mode (APPLY_MAX)\n",
    "\n",
    "# TODO: Use logits from USE_SAMPLES APPLY_MEAN before taking the mean, and train a logistic regression with that (crazy I know)\n",
    "\n",
    "BETA_DIR_NAME = \"results\"\n",
    "# This FEATURES needs to correspond with the betas (first element is beta1, second is beta2, etc...)\n",
    "FEATURES = ['runtime', 'actor_name_score', 'studio_score','crew_member_score', 'season_autumn', \n",
    "            'season_spring','season_summer']\n",
    "\n",
    "data_test = pd.read_csv('dataset/test.csv')\n",
    "y = data_test[\"target\"].values\n",
    "priors = pd.read_csv('dataset/model.csv')\n",
    "betas_samples = {\"Intercept\": priors[\"beta0\"].values}\n",
    "for i in range(len(FEATURES)):\n",
    "    betas_samples[FEATURES[i]] = priors[\"beta[\"+str(i+1)+\"]\"].values\n",
    "\n",
    "if USE_MODE:\n",
    "\n",
    "    betas_modes = {}\n",
    "    for key in betas_samples.keys():\n",
    "        betas_modes[key] = stats.mode(betas_samples[key])[0][0]\n",
    "\n",
    "    z = betas_modes[\"Intercept\"]\n",
    "    for key in FEATURES:\n",
    "        z += betas_modes[key] * data_test[key].values\n",
    "    logits = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    logits_copy = np.copy(logits)\n",
    "    logits_copy[logits_copy >= USE_MODE_THRESHOLD] = 1\n",
    "    logits_copy[logits_copy < USE_MODE_THRESHOLD] = 0\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y, logits_copy), \", Recall:\", recall_score(y, logits_copy))\n",
    "    print(pd.crosstab(y, logits_copy, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "    while input(\"You used {} threshold... Would you like to get the results for another one? ([y]/n) \".format(USE_MODE_THRESHOLD)) != \"n\":\n",
    "        USE_MODE_THRESHOLD = float(input(\"Enter threshold: \"))\n",
    "        logits_copy = np.copy(logits)\n",
    "        logits_copy[logits_copy >= USE_MODE_THRESHOLD] = 1\n",
    "        logits_copy[logits_copy < USE_MODE_THRESHOLD] = 0\n",
    "        print(\"Accuracy:\", accuracy_score(y, logits_copy), \", Recall:\", recall_score(y, logits_copy))\n",
    "        print(pd.crosstab(y, logits_copy, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "if USE_SAMPLES:\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    # betas_samples (as a Numpy Array) is 15000 x (len(FEATURES) + 1)\n",
    "    # data_test (as a Numpy Array) is 18463 x len(FEATURES)\n",
    "    b_samples = np.empty((len(betas_samples[FEATURES[0]]), (1 + len(FEATURES))))\n",
    "    for i, key in enumerate(betas_samples.keys()):\n",
    "        b_samples[:, i] = betas_samples[key]\n",
    "    z_samples = b_samples[:, 0] + np.dot(data_test[FEATURES].values, b_samples[:, 1:].T)\n",
    "\n",
    "    if APPLY_MODE:\n",
    "        z_modes = stats.mode(z_samples.T)[0]\n",
    "        logits = 1 / (1 + np.exp(-z_modes))\n",
    "    if APPLY_MEAN:\n",
    "        logits_samples = 1 / (1 + np.exp(-z_samples))\n",
    "        logits = np.mean(logits_samples, axis=1)\n",
    "    if APPLY_MAX:\n",
    "        logits_samples = 1 / (1 + np.exp(-z_samples))\n",
    "        logits_samples_copy = np.copy(logits_samples)\n",
    "        logits_samples_copy[logits_samples_copy >= USE_SAMPLES_THRESHOLD] = 1\n",
    "        logits_samples_copy[logits_samples_copy < USE_SAMPLES_THRESHOLD] = 0\n",
    "        y_pred = stats.mode(logits_samples_copy.T)[0].reshape(-1)\n",
    "    else:\n",
    "        logits_copy = np.copy(logits)\n",
    "        logits_copy[logits_copy >= USE_SAMPLES_THRESHOLD] = 1\n",
    "        logits_copy[logits_copy < USE_SAMPLES_THRESHOLD] = 0\n",
    "        y_pred = logits_copy.reshape(-1)\n",
    "\n",
    "    print(time() - start)\n",
    "    print(\"Accuracy:\", accuracy_score(y, y_pred), \", Recall:\", recall_score(y, y_pred))\n",
    "    print(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "    while input(\"You used {} threshold... Would you like to get the results for another one? ([y]/n) \".format(USE_SAMPLES_THRESHOLD)) != \"n\":\n",
    "        USE_SAMPLES_THRESHOLD = float(input(\"Enter threshold: \"))\n",
    "        if APPLY_MAX:\n",
    "            logits_samples_copy = np.copy(logits_samples)\n",
    "            logits_samples_copy[logits_samples_copy >= USE_SAMPLES_THRESHOLD] = 1\n",
    "            logits_samples_copy[logits_samples_copy < USE_SAMPLES_THRESHOLD] = 0\n",
    "            y_pred = stats.mode(logits_samples_copy.T)[0].reshape(-1)\n",
    "            score = roc_auc_score(y, y_pred)\n",
    "        else:\n",
    "            logits_copy = np.copy(logits)\n",
    "            logits_copy[logits_copy >= USE_SAMPLES_THRESHOLD] = 1\n",
    "            logits_copy[logits_copy < USE_SAMPLES_THRESHOLD] = 0\n",
    "            y_pred = logits_copy.reshape(-1)\n",
    "            score = roc_auc_score(y, y_pred)\n",
    "        print(\"Accuracy:\", accuracy_score(y, y_pred), \", Recall:\", recall_score(y, y_pred))\n",
    "        print(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "        print('AUC Score: {}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
